{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoz17Ext6TpF"
   },
   "source": [
    "# Предсказание эмоции в реальном времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "try:\n",
    "    import cv2\n",
    "except ModuleNotFoundError:\n",
    "    ! pip install opencv-python\n",
    "    import cv2\n",
    "    \n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    ! pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\user\\skillbox_thesis_project\\import_model.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем модуль import_ipynb и импортируем его.\n",
    "# Он необходим для импорта файлов .ipynb.\n",
    "try:\n",
    "    import import_ipynb\n",
    "except:\n",
    "    ! pip install import-ipynb\n",
    "    import import_ipynb\n",
    "\n",
    "# Если проект отсутствует, клонируем его с Github. Далее из проекта нам понадобиться файл \n",
    "# импорта модели - import_model.ipynb, расположенный в корне проекта.\n",
    "# Импортируем из него класс Model\n",
    "try:\n",
    "    from skillbox_thesis_project.import_model import Model\n",
    "except ModuleNotFoundError:\n",
    "    ! git clone https://github.com/GrinkoL/skillbox_thesis_project.git\n",
    "    from skillbox_thesis_project.import_model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-HDQxtpZKGuKWQhsiDANyc41SL_CwHdU\n",
      "To: C:\\Users\\user\\model.zip\n",
      "1.34GB [12:06, 1.84MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель предсказания эмоции.\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение к камере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Камера запущена\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1080) # Устанавливаем ширину кадра (по умолчанию - 640 пикселей)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720) # Устанавливаем высоту кадра (по умолчанию - 480 пикселей)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    print(\"Не удалось открыть камеру\")\n",
    "else:\n",
    "    print(\"Камера запущена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализаци детектора лиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем файл классического детектора лиц основанный на методе Виолы-Джонсона и признаках Хаара.\n",
    "if os.name == 'nt': # если Windows\n",
    "    url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
    "    filename = 'haarcascade_frontalface_default.xml'\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "elif os.name == 'posix': # если Linux\n",
    "    !wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "else:\n",
    "    raise Exception('Этот ноутбук должен быть запущен либо на Linux либо на Windows (7 и старше) операционной системе')\n",
    "\n",
    "# Иницилизируем детектор:\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск видео и отображение имоции в реальном времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В бесконечном цикле считываем кадр с камеры и выводим его, используя cv2.imshow()\n",
    "# корректная остановка окна с камерой произойдет, когда мы нажмем q на клавиатуре \n",
    "\n",
    "while(True):\n",
    "    # получение кадра с камеры\n",
    "    ret, frame = cam.read()\n",
    "    # получение координат лиц на кадре\n",
    "    grayscale_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(grayscale_image, 1.3, 5)\n",
    "    # Запускаем обработку кадров моделью только в случае детекции лиц.\n",
    "    # Если лица обнаружены, то faces указывает на данные типа np.ndarray, в противном случае -\n",
    "    # на пустой tuple.\n",
    "    if isinstance(faces, np.ndarray) : \n",
    "        one_face = faces[0] # будем учитывать только первое детектируемое лицо\n",
    "        x, y, w, h = one_face\n",
    "        #  Подготавливаем изображение для модели: выризаем лицо, меняем очерёдность цветовых слоём.\n",
    "        face_boundingbox_bgr = frame[y:y + h, x:x + w]\n",
    "        face_boundingbox_rgb = cv2.cvtColor(face_boundingbox_bgr, cv2.COLOR_BGR2RGB)\n",
    "        # Запуск предсказания - получение эмоции на текущем кадре.\n",
    "        emotion = model.predict(face_boundingbox_rgb.astype('float32'))\n",
    "        # Рисуем на кадре bounding-box лица.\n",
    "        frame = cv2.rectangle(frame, (x, y), (x + h, y + w), (0,255,0), 3)\n",
    "        # Добавляем текст - распознанную эмоцию\n",
    "        frame = cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    # Отображаем кадр\n",
    "    cv2.imshow(\"facial emotion recognition\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LBWvRa2F6Hum",
    "XlhQNj2wR1Ch",
    "XoNrAPKmVTr0",
    "nJ7WYvhHSTVP"
   ],
   "name": "Туториал по opencv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
